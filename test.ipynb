{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"V1.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "from textwrap import dedent\n",
    "import moviepy.editor as mp\n",
    "from pydub import AudioSegment\n",
    "import speech_recognition as sr\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from crewai import Agent, Task, Process, Crew\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Text From Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_video(video_path):\n",
    "    recognizer = sr.Recognizer()\n",
    "    \n",
    "    video = mp.VideoFileClip(video_path)\n",
    "    audio_path = \"temp_audio.wav\"\n",
    "    video.audio.write_audiofile(audio_path)\n",
    "    \n",
    "    transcript = \"\"\n",
    "    try:\n",
    "        with sr.AudioFile(audio_path) as source:\n",
    "            audio = recognizer.record(source)\n",
    "        transcript = recognizer.recognize_google(audio)\n",
    "    except sr.UnknownValueError:\n",
    "        transcript = \"Google Speech Recognition could not understand audio\"\n",
    "    except sr.RequestError as e:\n",
    "        transcript = f\"Could not request results from Google Speech Recognition service; {e}\"\n",
    "    finally:\n",
    "        if os.path.exists(audio_path):\n",
    "            os.remove(audio_path)\n",
    "    \n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting captions from LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROQ_API_KEY = \"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\"\n",
    "Text_Input = \"\"\"I love you Grand rising good Vibes to all status I'm ok happy Monday Happy Tuesday happy Wednesday happy Thursday happy Friday and a good New Year everyone\"\"\"\n",
    "LLM_Model = \"llama3-70b-8192\"\n",
    "def create_gif_caption_identifier_task(api_key, model, text_input):\n",
    "    LLM_Grouq = ChatGroq(\n",
    "        api_key=api_key,\n",
    "        model=model\n",
    "    )\n",
    "\n",
    "    GIF_caption_identifier = Agent(\n",
    "        role=\"GIF Caption Finder\",\n",
    "        goal=\"Identify sentences that can be used as text over GIFs\",\n",
    "        backstory=dedent(\"\"\"\\\n",
    "            You're a GIF caption expert tasked with identifying sentences that are ideal for adding text overlays to GIFs. \n",
    "            Your role is crucial in selecting text fragments that convey impactful and memorable messages to enhance the visual appeal and communication of the GIFs. \n",
    "            Your task is to carefully read the provided text and list all sentences that are suitable for GIF captions, ensuring they are concise, relevant, and engaging.\n",
    "        \"\"\"),\n",
    "        verbose=True,\n",
    "        allow_delegation=True,\n",
    "        llm=LLM_Grouq,\n",
    "        memory=True,\n",
    "    )\n",
    "\n",
    "    GIF_caption_identifier_Task = Task(\n",
    "        description=dedent(f\"\"\"\\\n",
    "            **INPUT:**\n",
    "                * **Text:**\n",
    "                    {text_input}\n",
    "            **TASK:**\n",
    "                Identify sentences within the text that can be used as captions for GIFs. ENSURE THE SELECTED SENTENCES ARE EXACTLY AS IN THE INPUT TEXT. NO SINGLE WORD OR LETTER SHOULD BE DIFFERENT OR NEW.\n",
    "\n",
    "            **OUTPUT:**\n",
    "                Output the selected sentences as a JSON object, with each sentence being a separate entry.\n",
    "            \n",
    "            **EXAMPLE OUTPUT:**\n",
    "                {{\n",
    "                    \"captions\": [\n",
    "                        \"This is a perfect moment!\",\n",
    "                        \"I can't believe this is happening.\",\n",
    "                        \"Let's make this unforgettable.\"\n",
    "                    ]\n",
    "                }}\n",
    "        \"\"\"),\n",
    "        agent=GIF_caption_identifier,\n",
    "        expected_output=dedent(\"\"\"\\\n",
    "            {\n",
    "                \"captions\": [\n",
    "                    \"Sentence 1\",\n",
    "                    \"Sentence 2\",\n",
    "                    ...\n",
    "                    \"Sentence n\"\n",
    "                ]\n",
    "            }\n",
    "        \"\"\"),\n",
    "        async_execution=False\n",
    "    )\n",
    "\n",
    "    crew = Crew(\n",
    "        agents=[GIF_caption_identifier],\n",
    "        tasks=[GIF_caption_identifier_Task],\n",
    "        verbose=2,\n",
    "        process=Process.sequential,\n",
    "    )\n",
    "\n",
    "    crew_result = crew.kickoff()\n",
    "\n",
    "    return crew_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the exact clips for each gif line also respective list of captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_from_video(video_path, audio_path):\n",
    "    video = VideoFileClip(video_path)\n",
    "    video.audio.write_audiofile(audio_path)\n",
    "\n",
    "def transcribe_audio_chunk(recognizer, audio_chunk):\n",
    "    with sr.AudioFile(audio_chunk) as source:\n",
    "        audio_data = recognizer.record(source)\n",
    "        try:\n",
    "            return recognizer.recognize_google(audio_data).lower()\n",
    "        except sr.UnknownValueError:\n",
    "            return \"\"\n",
    "\n",
    "def find_sentence_times(audio_path, target_sentence, initial_chunk_duration=2000, max_chunk_duration=10000):\n",
    "    recognizer = sr.Recognizer()\n",
    "    audio = AudioSegment.from_file(audio_path)\n",
    "    \n",
    "    audio_length = len(audio)\n",
    "    target_sentence = target_sentence.lower()\n",
    "    target_sentence_words = len(target_sentence.split())\n",
    "    \n",
    "    start_time = None\n",
    "    end_time = None\n",
    "    \n",
    "    chunk_duration = initial_chunk_duration\n",
    "    overlap_duration = initial_chunk_duration // 2  # 50% overlap\n",
    "    \n",
    "    while chunk_duration <= max_chunk_duration:\n",
    "        for i in range(0, audio_length, chunk_duration - overlap_duration):  # Overlapping chunks\n",
    "            chunk = audio[i:i+chunk_duration]\n",
    "            chunk.export(\"chunk.wav\", format=\"wav\")\n",
    "            \n",
    "            text = transcribe_audio_chunk(recognizer, \"chunk.wav\")\n",
    "            \n",
    "            if target_sentence in text:\n",
    "                words = text.split()\n",
    "                sentence_start_index = text.find(target_sentence)\n",
    "                sentence_end_index = sentence_start_index + len(target_sentence)\n",
    "                \n",
    "                start_time = i / 1000.0 + sentence_start_index / len(text) * chunk_duration / 1000.0\n",
    "                end_time = i / 1000.0 + sentence_end_index / len(text) * chunk_duration / 1000.0\n",
    "                \n",
    "                break\n",
    "        if start_time is not None:\n",
    "            break\n",
    "        chunk_duration += 1000  # Increase chunk duration by 1 second if the sentence is not found\n",
    "    \n",
    "    return start_time, end_time\n",
    "\n",
    "def save_video_clip(video_path, start_time, end_time, output_path):\n",
    "    video = VideoFileClip(video_path)\n",
    "    clip = video.subclip(start_time, end_time)\n",
    "    clip.write_videofile(output_path, codec=\"libx264\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_text_to_video(caption, video_path, output_path, font=cv2.FONT_HERSHEY_SIMPLEX):\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error opening video file: {video_path}\")\n",
    "        return\n",
    "\n",
    "    # Get video properties\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    \n",
    "    # Define the codec and create VideoWriter object\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Add text to the frame\n",
    "        font_scale = 3\n",
    "        font_color = (255, 255, 255)  # White color\n",
    "        thickness = 9\n",
    "        text_size = cv2.getTextSize(caption, font, font_scale, thickness)[0]\n",
    "        text_x = (frame_width - text_size[0]) // 2\n",
    "        text_y = frame_height - 160\n",
    "        \n",
    "        cv2.putText(frame, caption, (text_x, text_y), font, font_scale, font_color, thickness, cv2.LINE_AA)\n",
    "        \n",
    "        # Write the frame into the file\n",
    "        out.write(frame)\n",
    "    \n",
    "    # Release the video objects\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"Processed video saved as {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting them into Gifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mp4_to_gif(mp4_file, speed_factor=4):\n",
    "    gif_file = mp4_file.replace('.mp4', '.gif')\n",
    "    clip = VideoFileClip(mp4_file)\n",
    "    clip = clip.speedx(factor=speed_factor)\n",
    "    clip.write_gif(gif_file)\n",
    "    print(f\"Converted {mp4_file} to {gif_file} with speed factor {speed_factor}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "I love you Grand rising good Vibes to all status I'm ok happy Monday Happy Tuesday happy Wednesday happy Thursday happy Friday and a good New Year everyone\n"
     ]
    }
   ],
   "source": [
    "Text_Transcript = (transcribe_video(\"V1.mp4\"))\n",
    "print(Text_Transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m [2024-06-21 17:00:57][DEBUG]: == Working Agent: GIF Caption Finder\u001b[00m\n",
      "\u001b[1m\u001b[95m [2024-06-21 17:00:57][INFO]: == Starting Task: **INPUT:**\n",
      "    * **Text:**\n",
      "        I love you Grand rising good Vibes to all status I'm ok happy Monday Happy Tuesday happy Wednesday happy Thursday happy Friday and a good New Year everyone\n",
      "**TASK:**\n",
      "    Identify sentences within the text that can be used as captions for GIFs. ENSURE THE SELECTED SENTENCES ARE EXACTLY AS IN THE INPUT TEXT. NO SINGLE WORD OR LETTER SHOULD BE DIFFERENT OR NEW.\n",
      "\n",
      "**OUTPUT:**\n",
      "    Output the selected sentences as a JSON object, with each sentence being a separate entry.\n",
      "\n",
      "**EXAMPLE OUTPUT:**\n",
      "    {\n",
      "        \"captions\": [\n",
      "            \"This is a perfect moment!\",\n",
      "            \"I can't believe this is happening.\",\n",
      "            \"Let's make this unforgettable.\"\n",
      "        ]\n",
      "    }\n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI understand the task and its importance!\n",
      "\n",
      "Thought: I now can give a great answer\n",
      "\n",
      "After carefully reading the provided text, I have identified the following sentences that are suitable for GIF captions:\n",
      "\n",
      "Final Answer: \n",
      "{\n",
      "    \"captions\": [\n",
      "        \"Grand rising good Vibes to all\",\n",
      "        \"I'm ok\",\n",
      "        \"Happy Monday\",\n",
      "        \"Happy Tuesday\",\n",
      "        \"Happy Wednesday\",\n",
      "        \"Happy Thursday\",\n",
      "        \"Happy Friday\",\n",
      "        \"And a good New Year everyone\"\n",
      "    ]\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[1m\u001b[92m [2024-06-21 17:00:58][DEBUG]: == [GIF Caption Finder] Task output: {\n",
      "    \"captions\": [\n",
      "        \"Grand rising good Vibes to all\",\n",
      "        \"I'm ok\",\n",
      "        \"Happy Monday\",\n",
      "        \"Happy Tuesday\",\n",
      "        \"Happy Wednesday\",\n",
      "        \"Happy Thursday\",\n",
      "        \"Happy Friday\",\n",
      "        \"And a good New Year everyone\"\n",
      "    ]\n",
      "}\n",
      "\n",
      "\u001b[00m\n",
      "{\n",
      "    \"captions\": [\n",
      "        \"Grand rising good Vibes to all\",\n",
      "        \"I'm ok\",\n",
      "        \"Happy Monday\",\n",
      "        \"Happy Tuesday\",\n",
      "        \"Happy Wednesday\",\n",
      "        \"Happy Thursday\",\n",
      "        \"Happy Friday\",\n",
      "        \"And a good New Year everyone\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "GIF_Sentences = (create_gif_caption_identifier_task(GROQ_API_KEY, LLM_Model, Text_Transcript))\n",
    "print(GIF_Sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Grand rising good Vibes to all', \"I'm ok\", 'Happy Monday', 'Happy Tuesday', 'Happy Wednesday', 'Happy Thursday', 'Happy Friday', 'And a good New Year everyone']\n"
     ]
    }
   ],
   "source": [
    "temp = json.loads(GIF_Sentences)\n",
    "GIF_Sentences_LIST = temp[\"captions\"]\n",
    "print(GIF_Sentences_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Building video output_clip_1.mp4.\n",
      "MoviePy - Writing audio in output_clip_1TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video output_clip_1.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output_clip_1.mp4\n",
      "The sentence 'Grand rising good Vibes to all' starts at 6.0 seconds and ends at 13.0 seconds. Saved to output_clip_1.mp4\n",
      "The sentence 'I'm ok' was not found in the audio.\n",
      "Moviepy - Building video output_clip_3.mp4.\n",
      "MoviePy - Writing audio in output_clip_3TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video output_clip_3.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output_clip_3.mp4\n",
      "The sentence 'Happy Monday' starts at 30.0 seconds and ends at 32.0 seconds. Saved to output_clip_3.mp4\n",
      "Moviepy - Building video output_clip_4.mp4.\n",
      "MoviePy - Writing audio in output_clip_4TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video output_clip_4.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output_clip_4.mp4\n",
      "The sentence 'Happy Tuesday' starts at 33.0 seconds and ends at 35.0 seconds. Saved to output_clip_4.mp4\n",
      "Moviepy - Building video output_clip_5.mp4.\n",
      "MoviePy - Writing audio in output_clip_5TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video output_clip_5.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output_clip_5.mp4\n",
      "The sentence 'Happy Wednesday' starts at 34.0 seconds and ends at 36.0 seconds. Saved to output_clip_5.mp4\n",
      "Moviepy - Building video output_clip_6.mp4.\n",
      "MoviePy - Writing audio in output_clip_6TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video output_clip_6.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output_clip_6.mp4\n",
      "The sentence 'Happy Thursday' starts at 36.0 seconds and ends at 38.0 seconds. Saved to output_clip_6.mp4\n",
      "Moviepy - Building video output_clip_7.mp4.\n",
      "MoviePy - Writing audio in output_clip_7TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video output_clip_7.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output_clip_7.mp4\n",
      "The sentence 'Happy Friday' starts at 38.0 seconds and ends at 40.0 seconds. Saved to output_clip_7.mp4\n",
      "The sentence 'And a good New Year everyone' was not found in the audio.\n",
      "{'Grand rising good Vibes to all': 'output_clip_1.mp4', 'Happy Monday': 'output_clip_3.mp4', 'Happy Tuesday': 'output_clip_4.mp4', 'Happy Wednesday': 'output_clip_5.mp4', 'Happy Thursday': 'output_clip_6.mp4', 'Happy Friday': 'output_clip_7.mp4'}\n"
     ]
    }
   ],
   "source": [
    "video_path = \"V1.mp4\"\n",
    "audio_path = \"audio.wav\"\n",
    "\n",
    "extract_audio_from_video(video_path, audio_path)\n",
    "\n",
    "clips_paths = {}\n",
    "\n",
    "for i, caption in enumerate(GIF_Sentences_LIST, 1):\n",
    "    start_time, end_time = find_sentence_times(audio_path, caption)\n",
    "    if start_time is not None:\n",
    "        output_path = f\"output_clip_{i}.mp4\"\n",
    "        save_video_clip(video_path, start_time, end_time, output_path)\n",
    "        clips_paths[caption] = output_path\n",
    "        print(f\"The sentence '{caption}' starts at {start_time} seconds and ends at {end_time} seconds. Saved to {output_path}\")\n",
    "    else:\n",
    "        print(f\"The sentence '{caption}' was not found in the audio.\")\n",
    "\n",
    "print(clips_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed video saved as output_Grand_rising_good_Vibes_to_all.mp4\n",
      "Processed video saved as output_Happy_Monday.mp4\n",
      "Processed video saved as output_Happy_Tuesday.mp4\n",
      "Processed video saved as output_Happy_Wednesday.mp4\n",
      "Processed video saved as output_Happy_Thursday.mp4\n",
      "Processed video saved as output_Happy_Friday.mp4\n",
      "['output_Grand_rising_good_Vibes_to_all.mp4', 'output_Happy_Monday.mp4', 'output_Happy_Tuesday.mp4', 'output_Happy_Wednesday.mp4', 'output_Happy_Thursday.mp4', 'output_Happy_Friday.mp4']\n"
     ]
    }
   ],
   "source": [
    "clips_paths_Captioned = []\n",
    "\n",
    "for caption, video_path in clips_paths.items():\n",
    "    output_path = f\"output_{caption.replace(' ', '_')}.mp4\"\n",
    "    clips_paths_Captioned.append(output_path)\n",
    "    add_text_to_video(caption, video_path, output_path, font=cv2.FONT_HERSHEY_SIMPLEX)\n",
    "\n",
    "print(clips_paths_Captioned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building file output_Grand_rising_good_Vibes_to_all.gif with imageio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted output_Grand_rising_good_Vibes_to_all.mp4 to output_Grand_rising_good_Vibes_to_all.gif with speed factor 4\n",
      "MoviePy - Building file output_Happy_Monday.gif with imageio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted output_Happy_Monday.mp4 to output_Happy_Monday.gif with speed factor 4\n",
      "MoviePy - Building file output_Happy_Tuesday.gif with imageio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted output_Happy_Tuesday.mp4 to output_Happy_Tuesday.gif with speed factor 4\n",
      "MoviePy - Building file output_Happy_Wednesday.gif with imageio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted output_Happy_Wednesday.mp4 to output_Happy_Wednesday.gif with speed factor 4\n",
      "MoviePy - Building file output_Happy_Thursday.gif with imageio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted output_Happy_Thursday.mp4 to output_Happy_Thursday.gif with speed factor 4\n",
      "MoviePy - Building file output_Happy_Friday.gif with imageio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted output_Happy_Friday.mp4 to output_Happy_Friday.gif with speed factor 4\n"
     ]
    }
   ],
   "source": [
    "for mp4_file in clips_paths_Captioned:\n",
    "    convert_mp4_to_gif(mp4_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
