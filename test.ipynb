{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"V1.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from textwrap import dedent\n",
    "import moviepy.editor as mp\n",
    "from pydub import AudioSegment\n",
    "import speech_recognition as sr\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from crewai import Agent, Task, Process, Crew\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Text From Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_video(video_path):\n",
    "    recognizer = sr.Recognizer()\n",
    "    \n",
    "    video = mp.VideoFileClip(video_path)\n",
    "    audio_path = \"temp_audio.wav\"\n",
    "    video.audio.write_audiofile(audio_path)\n",
    "    \n",
    "    transcript = \"\"\n",
    "    try:\n",
    "        with sr.AudioFile(audio_path) as source:\n",
    "            audio = recognizer.record(source)\n",
    "        transcript = recognizer.recognize_google(audio)\n",
    "    except sr.UnknownValueError:\n",
    "        transcript = \"Google Speech Recognition could not understand audio\"\n",
    "    except sr.RequestError as e:\n",
    "        transcript = f\"Could not request results from Google Speech Recognition service; {e}\"\n",
    "    finally:\n",
    "        if os.path.exists(audio_path):\n",
    "            os.remove(audio_path)\n",
    "    \n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting captions from LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROQ_API_KEY = \"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\"\n",
    "Text_Input = \"\"\"I love you Grand rising good Vibes to all status I'm ok happy Monday Happy Tuesday happy Wednesday happy Thursday happy Friday and a good New Year everyone\"\"\"\n",
    "LLM_Model = \"llama3-70b-8192\"\n",
    "def create_gif_caption_identifier_task(api_key, model, text_input):\n",
    "    LLM_Grouq = ChatGroq(\n",
    "        api_key=api_key,\n",
    "        model=model\n",
    "    )\n",
    "\n",
    "    GIF_caption_identifier = Agent(\n",
    "        role=\"GIF Caption Finder\",\n",
    "        goal=\"Identify sentences that can be used as text over GIFs\",\n",
    "        backstory=dedent(\"\"\"\\\n",
    "            You're a GIF caption expert tasked with identifying sentences that are ideal for adding text overlays to GIFs. \n",
    "            Your role is crucial in selecting text fragments that convey impactful and memorable messages to enhance the visual appeal and communication of the GIFs. \n",
    "            Your task is to carefully read the provided text and list all sentences that are suitable for GIF captions, ensuring they are concise, relevant, and engaging.\n",
    "        \"\"\"),\n",
    "        verbose=True,\n",
    "        allow_delegation=True,\n",
    "        llm=LLM_Grouq,\n",
    "        memory=True,\n",
    "    )\n",
    "\n",
    "    GIF_caption_identifier_Task = Task(\n",
    "        description=dedent(f\"\"\"\\\n",
    "            **INPUT:**\n",
    "                * **Text:**\n",
    "                    {text_input}\n",
    "            **TASK:**\n",
    "                Identify sentences within the text that can be used as captions for GIFs. ENSURE THE SELECTED SENTENCES ARE EXACTLY AS IN THE INPUT TEXT. NO SINGLE WORD OR LETTER SHOULD BE DIFFERENT OR NEW, and the sentences should be impactful, very short and contextually appropriate for a GIF.\n",
    "\n",
    "            **OUTPUT:**\n",
    "                Output the selected sentences as a JSON object, with each sentence being a separate entry.\n",
    "            \n",
    "            **EXAMPLE OUTPUT:**\n",
    "                {{\n",
    "                    \"captions\": [\n",
    "                        \"This is a perfect moment!\",\n",
    "                        \"I can't believe this is happening.\",\n",
    "                        \"Let's make this unforgettable.\"\n",
    "                    ]\n",
    "                }}\n",
    "        \"\"\"),\n",
    "        agent=GIF_caption_identifier,\n",
    "        expected_output=dedent(\"\"\"\\\n",
    "            {\n",
    "                \"captions\": [\n",
    "                    \"Sentence 1\",\n",
    "                    \"Sentence 2\",\n",
    "                    ...\n",
    "                    \"Sentence n\"\n",
    "                ]\n",
    "            }\n",
    "        \"\"\"),\n",
    "        async_execution=False\n",
    "    )\n",
    "\n",
    "    crew = Crew(\n",
    "        agents=[GIF_caption_identifier],\n",
    "        tasks=[GIF_caption_identifier_Task],\n",
    "        verbose=2,\n",
    "        process=Process.sequential,\n",
    "    )\n",
    "\n",
    "    crew_result = crew.kickoff()\n",
    "\n",
    "    return crew_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the exact clips for each gif line also respective list of captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_from_video(video_path, audio_path):\n",
    "    video = VideoFileClip(video_path)\n",
    "    video.audio.write_audiofile(audio_path)\n",
    "\n",
    "def transcribe_audio_chunk(recognizer, audio_chunk):\n",
    "    with sr.AudioFile(audio_chunk) as source:\n",
    "        audio_data = recognizer.record(source)\n",
    "        try:\n",
    "            return recognizer.recognize_google(audio_data).lower()\n",
    "        except sr.UnknownValueError:\n",
    "            return \"\"\n",
    "\n",
    "def find_sentence_times(audio_path, target_sentence, initial_chunk_duration=2000, max_chunk_duration=10000):\n",
    "    recognizer = sr.Recognizer()\n",
    "    audio = AudioSegment.from_file(audio_path)\n",
    "    \n",
    "    audio_length = len(audio)\n",
    "    target_sentence = target_sentence.lower()\n",
    "    target_sentence_words = len(target_sentence.split())\n",
    "    \n",
    "    start_time = None\n",
    "    end_time = None\n",
    "    \n",
    "    chunk_duration = initial_chunk_duration\n",
    "    overlap_duration = initial_chunk_duration // 2  # 50% overlap\n",
    "    \n",
    "    while chunk_duration <= max_chunk_duration:\n",
    "        for i in range(0, audio_length, chunk_duration - overlap_duration):  # Overlapping chunks\n",
    "            chunk = audio[i:i+chunk_duration]\n",
    "            chunk.export(\"chunk.wav\", format=\"wav\")\n",
    "            \n",
    "            text = transcribe_audio_chunk(recognizer, \"chunk.wav\")\n",
    "            \n",
    "            if target_sentence in text:\n",
    "                words = text.split()\n",
    "                sentence_start_index = text.find(target_sentence)\n",
    "                sentence_end_index = sentence_start_index + len(target_sentence)\n",
    "                \n",
    "                start_time = i / 1000.0 + sentence_start_index / len(text) * chunk_duration / 1000.0\n",
    "                end_time = i / 1000.0 + sentence_end_index / len(text) * chunk_duration / 1000.0\n",
    "                \n",
    "                break\n",
    "        if start_time is not None:\n",
    "            break\n",
    "        chunk_duration += 1000  # Increase chunk duration by 1 second if the sentence is not found\n",
    "    \n",
    "    return start_time, end_time\n",
    "\n",
    "def save_video_clip(video_path, start_time, end_time, output_path):\n",
    "    video = VideoFileClip(video_path)\n",
    "    clip = video.subclip(start_time, end_time)\n",
    "    clip.write_videofile(output_path, codec=\"libx264\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "I love you Grand rising good Vibes to all status I'm ok happy Monday Happy Tuesday happy Wednesday happy Thursday happy Friday and a good New Year everyone\n"
     ]
    }
   ],
   "source": [
    "Text_Transcript = (transcribe_video(\"V1.mp4\"))\n",
    "print(Text_Transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m [2024-06-21 15:44:48][DEBUG]: == Working Agent: GIF Caption Finder\u001b[00m\n",
      "\u001b[1m\u001b[95m [2024-06-21 15:44:48][INFO]: == Starting Task: **INPUT:**\n",
      "    * **Text:**\n",
      "        I love you Grand rising good Vibes to all status I'm ok happy Monday Happy Tuesday happy Wednesday happy Thursday happy Friday and a good New Year everyone\n",
      "**TASK:**\n",
      "    Identify sentences within the text that can be used as captions for GIFs. ENSURE THE SELECTED SENTENCES ARE EXACTLY AS IN THE INPUT TEXT. NO SINGLE WORD OR LETTER SHOULD BE DIFFERENT OR NEW, and the sentences should be impactful, very short and contextually appropriate for a GIF.\n",
      "\n",
      "**OUTPUT:**\n",
      "    Output the selected sentences as a JSON object, with each sentence being a separate entry.\n",
      "\n",
      "**EXAMPLE OUTPUT:**\n",
      "    {\n",
      "        \"captions\": [\n",
      "            \"This is a perfect moment!\",\n",
      "            \"I can't believe this is happening.\",\n",
      "            \"Let's make this unforgettable.\"\n",
      "        ]\n",
      "    }\n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI understand the task!\n",
      "\n",
      "Thought: I now can give a great answer\n",
      "\n",
      "After carefully reading the provided text, I have identified the following sentences that are suitable for GIF captions:\n",
      "\n",
      "Final Answer: \n",
      "{\n",
      "    \"captions\": [\n",
      "        \"Grand rising\",\n",
      "        \"Happy Monday\",\n",
      "        \"Happy Tuesday\",\n",
      "        \"Happy Wednesday\",\n",
      "        \"Happy Thursday\",\n",
      "        \"Happy Friday\",\n",
      "        \"Good Vibes to all\",\n",
      "        \"I'm ok\",\n",
      "        \"Happy New Year everyone\"\n",
      "    ]\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[1m\u001b[92m [2024-06-21 15:44:49][DEBUG]: == [GIF Caption Finder] Task output: {\n",
      "    \"captions\": [\n",
      "        \"Grand rising\",\n",
      "        \"Happy Monday\",\n",
      "        \"Happy Tuesday\",\n",
      "        \"Happy Wednesday\",\n",
      "        \"Happy Thursday\",\n",
      "        \"Happy Friday\",\n",
      "        \"Good Vibes to all\",\n",
      "        \"I'm ok\",\n",
      "        \"Happy New Year everyone\"\n",
      "    ]\n",
      "}\n",
      "\n",
      "\u001b[00m\n",
      "{\n",
      "    \"captions\": [\n",
      "        \"Grand rising\",\n",
      "        \"Happy Monday\",\n",
      "        \"Happy Tuesday\",\n",
      "        \"Happy Wednesday\",\n",
      "        \"Happy Thursday\",\n",
      "        \"Happy Friday\",\n",
      "        \"Good Vibes to all\",\n",
      "        \"I'm ok\",\n",
      "        \"Happy New Year everyone\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "GIF_Sentences = (create_gif_caption_identifier_task(GROQ_API_KEY, LLM_Model, Text_Transcript))\n",
    "print(GIF_Sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Grand rising', 'Happy Monday', 'Happy Tuesday', 'Happy Wednesday', 'Happy Thursday', 'Happy Friday', 'Good Vibes to all', \"I'm ok\", 'Happy New Year everyone']\n"
     ]
    }
   ],
   "source": [
    "temp = json.loads(GIF_Sentences)\n",
    "GIF_Sentences_LIST = temp[\"captions\"]\n",
    "print(GIF_Sentences_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"V1.mp4\"\n",
    "audio_path = \"audio.wav\"\n",
    "\n",
    "extract_audio_from_video(video_path, audio_path)\n",
    "\n",
    "clips_paths = {}\n",
    "\n",
    "for i, caption in enumerate(GIF_Sentences_LIST, 1):\n",
    "    start_time, end_time = find_sentence_times(audio_path, caption)\n",
    "    if start_time is not None:\n",
    "        output_path = f\"output_clip_{i}.mp4\"\n",
    "        save_video_clip(video_path, start_time, end_time, output_path)\n",
    "        clips_paths[f\"caption_{i}\"] = output_path\n",
    "        print(f\"The sentence '{caption}' starts at {start_time} seconds and ends at {end_time} seconds. Saved to {output_path}\")\n",
    "    else:\n",
    "        print(f\"The sentence '{caption}' was not found in the audio.\")\n",
    "\n",
    "print(clips_paths)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
