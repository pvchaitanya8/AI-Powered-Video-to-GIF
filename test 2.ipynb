{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Building video output_clip_1.mp4.\n",
      "MoviePy - Writing audio in output_clip_1TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video output_clip_1.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output_clip_1.mp4\n",
      "The sentence 'I love you' starts at 0.0 seconds and ends at 2.0 seconds. Saved to output_clip_1.mp4\n",
      "Moviepy - Building video output_clip_2.mp4.\n",
      "MoviePy - Writing audio in output_clip_2TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video output_clip_2.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output_clip_2.mp4\n",
      "The sentence 'Happy Friday' starts at 38.0 seconds and ends at 40.0 seconds. Saved to output_clip_2.mp4\n",
      "{'caption_1': 'output_clip_1.mp4', 'caption_2': 'output_clip_2.mp4'}\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "def extract_audio_from_video(video_path, audio_path):\n",
    "    video = VideoFileClip(video_path)\n",
    "    video.audio.write_audiofile(audio_path)\n",
    "\n",
    "def transcribe_audio_chunk(recognizer, audio_chunk):\n",
    "    with sr.AudioFile(audio_chunk) as source:\n",
    "        audio_data = recognizer.record(source)\n",
    "        try:\n",
    "            return recognizer.recognize_google(audio_data).lower()\n",
    "        except sr.UnknownValueError:\n",
    "            return \"\"\n",
    "\n",
    "def find_sentence_times(audio_path, target_sentence, initial_chunk_duration=2000, max_chunk_duration=10000):\n",
    "    recognizer = sr.Recognizer()\n",
    "    audio = AudioSegment.from_file(audio_path)\n",
    "    \n",
    "    audio_length = len(audio)\n",
    "    target_sentence = target_sentence.lower()\n",
    "    target_sentence_words = len(target_sentence.split())\n",
    "    \n",
    "    start_time = None\n",
    "    end_time = None\n",
    "    \n",
    "    chunk_duration = initial_chunk_duration\n",
    "    overlap_duration = initial_chunk_duration // 2  # 50% overlap\n",
    "    \n",
    "    while chunk_duration <= max_chunk_duration:\n",
    "        for i in range(0, audio_length, chunk_duration - overlap_duration):  # Overlapping chunks\n",
    "            chunk = audio[i:i+chunk_duration]\n",
    "            chunk.export(\"chunk.wav\", format=\"wav\")\n",
    "            \n",
    "            text = transcribe_audio_chunk(recognizer, \"chunk.wav\")\n",
    "            \n",
    "            if target_sentence in text:\n",
    "                words = text.split()\n",
    "                sentence_start_index = text.find(target_sentence)\n",
    "                sentence_end_index = sentence_start_index + len(target_sentence)\n",
    "                \n",
    "                start_time = i / 1000.0 + sentence_start_index / len(text) * chunk_duration / 1000.0\n",
    "                end_time = i / 1000.0 + sentence_end_index / len(text) * chunk_duration / 1000.0\n",
    "                \n",
    "                break\n",
    "        if start_time is not None:\n",
    "            break\n",
    "        chunk_duration += 1000  # Increase chunk duration by 1 second if the sentence is not found\n",
    "    \n",
    "    return start_time, end_time\n",
    "\n",
    "def save_video_clip(video_path, start_time, end_time, output_path):\n",
    "    video = VideoFileClip(video_path)\n",
    "    clip = video.subclip(start_time, end_time)\n",
    "    clip.write_videofile(output_path, codec=\"libx264\")\n",
    "\n",
    "# Define the paths\n",
    "video_path = \"V1.mp4\"\n",
    "audio_path = \"audio.wav\"\n",
    "captions = [\n",
    "    \"I love you\",\n",
    "    \"Happy Friday\"\n",
    "]\n",
    "\n",
    "# Extract audio from video\n",
    "extract_audio_from_video(video_path, audio_path)\n",
    "\n",
    "# Dictionary to store the paths of the created video clips\n",
    "clips_paths = {}\n",
    "\n",
    "# Process each caption\n",
    "for i, caption in enumerate(captions, 1):\n",
    "    start_time, end_time = find_sentence_times(audio_path, caption)\n",
    "    if start_time is not None:\n",
    "        output_path = f\"output_clip_{i}.mp4\"\n",
    "        save_video_clip(video_path, start_time, end_time, output_path)\n",
    "        clips_paths[f\"caption_{i}\"] = output_path\n",
    "        print(f\"The sentence '{caption}' starts at {start_time} seconds and ends at {end_time} seconds. Saved to {output_path}\")\n",
    "    else:\n",
    "        print(f\"The sentence '{caption}' was not found in the audio.\")\n",
    "\n",
    "# Print the dictionary with paths\n",
    "print(clips_paths)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
